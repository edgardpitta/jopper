{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Document similarity analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOXZgsASOu9Z4rqFrHxqxFY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edgardpitta/jopper/blob/main/Document_similarity_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activity\n",
        "\n",
        "You will compare the similarity between your career materials (pitch, CV, LinkedIn profile, etc) and the job advertisement of your choice by calculating their **Similarity Index**.\n",
        "\n",
        "Document similarity is on a scale of 0 to 1, with 0 being completely different and 1 being an exact match. Each sentence has a 1 when compared to itself - they are totally the same!\n",
        "\n",
        "This script only works in English."
      ],
      "metadata": {
        "id": "A6My4bLrJEZq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions\n",
        "\n",
        "\n",
        "1.   In the '*Runtime/Environnement d'execution*' menu item, click '*Run all*'. This can take some time as it prepares your environment for the script to run.\n",
        "2.   When prompted, paste the job posting and your candidate material you want to compare with into the text fields and the script will run automatically.\n",
        "1.   Analyze the Similarity Index between the two documents. The closer to 1, the better.\n",
        "2.   Make adjustements to your candidate material and rerun the script from item 3, by clicking in '*Runtime/Environnement d'execution*' menu item '*Run from here/Courir Après*'\n",
        "\n",
        "**Print the page as a PDF and upload it to K2. This is a graded activity and you will not be graded if the activity is not loaded into K2.**\n",
        "\n",
        "Click here to download these instructions.\n",
        "\n"
      ],
      "metadata": {
        "id": "ck96LjaGOEuN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Prepare the environment. Run this only once."
      ],
      "metadata": {
        "id": "jAOWE56QKrwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "!pip install nltk\n",
        "!pip install gensim\n",
        "!pip install string\n",
        "!pip install sklearn"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Nbomfyl9Embi",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import nltk\n",
        "import gensim\n",
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LL91WKs0E66a",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Upload the **Job Posting** you want to compare with your candidate materials.\n",
        "\n",
        "Paste your job posting in the text box below and click 'Enter'.\n",
        "Paste only the relevant part of the posting."
      ],
      "metadata": {
        "id": "HVdbzVg6LIQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "posting = input()"
      ],
      "metadata": {
        "id": "ayEFxNyJHGkU",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "St549tqa_n8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Job Posting''s Key-words (lemmas)"
      ],
      "metadata": {
        "id": "75KTxPGXIBwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "posting_clean=[] \n",
        "new_sentence = []\n",
        " \n",
        " #Clean the corpus: eliminate stopwords, punctuations, symbols, ...\n",
        "stop_words = set(stopwords.words('english')+ list(string.punctuation)+list(\"\\n\") )\n",
        "words = word_tokenize(posting)\n",
        "words = [word.lower() for word in words if word.isalpha()]\n",
        "for word in words:\n",
        "  if word not in stop_words:    \n",
        "            \n",
        "#Reduce the tokens to their roots\n",
        "    s =lemmatizer.lemmatize(word)\n",
        "    new_sentence.append(s.lower())      \n",
        "posting_clean=\" \".join(new_sentence)\n",
        "posting_clean"
      ],
      "metadata": {
        "cellView": "form",
        "id": "T6jdvSCv_9A4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Upload your **Candidate Material** (pitch, CV, LinkedIn Profile)\n",
        "\n",
        "Paste your candidate material in the text box below and click 'Enter'"
      ],
      "metadata": {
        "id": "j0RmbGPHK-Rm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to make adjustments to your candidate materials to increase the Similatiy Index, just re-run all the cells from here by clicking 'Ctrl+F10' or in the menu item '*Runtime/Environnement d'exécution*', choose '*Run Selection/Courir Après*'."
      ],
      "metadata": {
        "id": "hicgqARSPvn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "pitch = input()"
      ],
      "metadata": {
        "id": "RiYWYI76HCFY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Candidate Material's Key-words (lemmas)"
      ],
      "metadata": {
        "id": "ivk7DcMfIOWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "pitch_clean=[]\n",
        "new_sentence2 = []\n",
        "\n",
        "#Clean the corpus: eliminate stopwords, punctuations, symbols, ...\n",
        "stop_words = set(stopwords.words('english')+ list(string.punctuation)+list(\"\\n\") )\n",
        "words = word_tokenize(pitch)\n",
        "words = [word.lower() for word in words if word.isalpha()]\n",
        "for word in words:\n",
        "  if word not in stop_words:    \n",
        "            \n",
        "#Reduce the tokens to their roots\n",
        "    s =lemmatizer.lemmatize(word)\n",
        "    new_sentence2.append(s.lower())      \n",
        "pitch_clean=\" \".join(new_sentence2)\n",
        "pitch_clean"
      ],
      "metadata": {
        "cellView": "form",
        "id": "86xSRpoHBQrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Calculate the **Similarity Index**\n",
        "\n",
        "Document similarity is on a scale of 0 to 1, with 0 being completely different and 1 being an exact match. The higher the score, the better, because that means the keywords that the employer searches for appear in your candidate materials."
      ],
      "metadata": {
        "id": "8vOIt5-1Lke1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "sentences = [\n",
        "    pitch_clean,\n",
        "    posting_clean,\n",
        "]"
      ],
      "metadata": {
        "id": "OAjqoAr0F0nj",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "\n",
        "vectorizer = CountVectorizer(binary=True)\n",
        "matrix = vectorizer.fit_transform(sentences)\n",
        "counts = pd.DataFrame(\n",
        "    matrix.toarray(),\n",
        "    index=sentences,\n",
        "    columns=vectorizer.get_feature_names())\n",
        "#counts"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Q6iBoQiUGZUr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Compute the similarities using the word counts\n",
        "similarities = cosine_similarity(matrix)\n",
        "\n",
        "# Make a fancy colored dataframe about it\n",
        "pd.DataFrame(similarities,\n",
        "             index=sentences,\n",
        "             columns=sentences) \\\n",
        "            .style \\\n",
        "            .background_gradient(axis=None)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5aV97LjHG1WV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How the script works\n",
        "\n",
        "To judge similarity between these sentences, we're going to use a TfidfVectorizer from scikit-learn. Less common words are stressed, more common words are more important, and words in long sentences mean less than words in short sentences. \n",
        "\n",
        "We'll be measuring similarity via cosine similarity, a standard measure of similarity in natural language processing. It's similar to how we might look at a graph with points at (0,0) and (2,3) and measure the distance between them - just a bit more complicated."
      ],
      "metadata": {
        "id": "GS4Ax_UMKRjv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Natural Language Processing - NLP Vocabulary\n",
        "\n",
        "**Tokenization** is a way of separating a piece of text into smaller units called tokens. Here, tokens can be either words, characters, or punctuation.\n",
        "\n",
        "The **lemma** is the form of the word found in dictionaries, sometimes called the base form. Introducing lemmas makes it possible to treat different word forms of the word as the same word.\n",
        "\n",
        "**Stopwords** are those words that do not provide any useful information to decide in which category a text should be classified. This may be either because they don't have any meaning (prepositions, conjunctions, etc.) or because they are too frequent in the classification context."
      ],
      "metadata": {
        "id": "B-m2-EyDJEWT"
      }
    }
  ]
}